{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loggloss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2BR1gp4pUcONFvXLbi98K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nKkPzItF05"
      },
      "source": [
        "''' Logistic Regression '''\n",
        "\n",
        "#calculating sigoid function g(z)=1/(1+e^(-z)\n",
        "\n",
        "def logistic_predicted(x,w):\n",
        "  return 1/(1+ pow(math.e,-(np.dot(x,w))))\n",
        "\n",
        "#updating co-eff (wj)\n",
        "def logistic_w_update(x,y,alpha,w):\n",
        "\n",
        "  for j in range(len(w)):\n",
        "    subtract_part = 0\n",
        "    for i in range(len(x)):\n",
        "      subtract_part = subtract_part + (logistic_predicted(x[i],w)-y[i])*x[i][j]*(logistic_predicted(x[i],w))*(1-logistic_predicted(x[i],w))\n",
        "\n",
        "    w[j] = w[j] - (alpha*subtract_part)/len(x)\n",
        "\n",
        "  return w\n",
        "#cost function\n",
        "def error_logistic(x,y,w):\n",
        "  J = 0\n",
        "\n",
        "\n",
        "  for i in range(len(x)):\n",
        "    J = J + (y[i]*math.log(logistic_predicted(x[i],w),10)) + ((1-y[i])*math.log(1-logistic_predicted(x[i],w),10))\n",
        "  J = -J/(len(x))\n",
        "\n",
        "  return J\n",
        "\n",
        "def logloss(df,w,alpha,rho,epochs,showPlot):\n",
        "\n",
        "  a = np.array(df.values)\n",
        "  x = a[:,0:len(a[0])-1]\n",
        "  y = a[:,len(a[0])-1]\n",
        "\n",
        "  J = 0\n",
        "  prevJ = 0\n",
        "  itr = 0\n",
        "  while True:\n",
        "\n",
        "    if(itr >= epochs):\n",
        "      break\n",
        "\n",
        "\n",
        "    h = []\n",
        "\n",
        "\n",
        "    for i in range(len(x)):\n",
        "\n",
        "      # predicted value must be changed\n",
        "      predicted_value = logistic_predicted(x[i],w)\n",
        "      # predicted_value = logistic_predicted(x[i],w)\n",
        "      h.append(predicted_value)\n",
        "\n",
        "      # gradient\n",
        "      # J = J + pow(predicted_value - y[i],2)\n",
        "\n",
        "      # stocastic - logloss\n",
        "      J = J + (y[i]*math.log(predicted_value,10)) + ((1-y[i])*math.log(1-predicted_value,10))\n",
        "\n",
        "      for j in range(len(w)):\n",
        "\n",
        "         # w[j] = w[j] - alpha*(predicted_value-y[i])*x[i][j]\n",
        "        # logloss-logistic, gradient-stocastic - MSE\n",
        "        # logistic - MSE\n",
        "         w[j] = w[j] - alpha*(predicted_value-y[i])*x[i][j]*predicted_value*(1-predicted_value)\n",
        "\n",
        "    # J = J/(2*len(x)) for batch grad\n",
        "    J = -J/(len(x)) #for stochastic\n",
        "\n",
        "    if(abs(J-prevJ) <= rho):\n",
        "      break\n",
        "\n",
        "    prevJ = J\n",
        "    itr = itr + 1\n",
        "\n",
        "  return J,w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vtqrbkwuDGm",
        "outputId": "2d5900aa-e854-494e-a61a-35b2cc73cc9e"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"Dataset.csv\")\n",
        "print(df)\n",
        "\n",
        "#Normalisation of data frame\n",
        "\n",
        "a=df['Target']\n",
        "print(a)\n",
        "df=df.drop(['Target'],axis=1)\n",
        "df = df/(df.max().max())\n",
        "df.insert(14,'Target',a)\n",
        "df.insert(loc=0,column='-1',value=[1 for i in range(len(df))])\n",
        "print(df)\n",
        "data_train,data_remaining = train_test_split(df,train_size = 0.3)\n",
        "data_test,data_validation = train_test_split(data_remaining,train_size = 0.28)\n",
        "#print(data_train)\n",
        "#print(data_validation)\n",
        "c={}\n",
        "for i in range(len(df['Target'])):\n",
        "  c=set(df['Target'])\n",
        "print(c)\n",
        "\n",
        "alphaarr = np.array([0.1,0.001,0.02,0.03,0.001])\n",
        "rhoarr = np.array([0.0001,0.0002,0.0003,0.0004,0.0005])\n",
        "epocharr = np.array([10,20,30,50,80])\n",
        "W=[]\n",
        "for i in range(df.shape[1]-1):\n",
        "     W.append(random.uniform(-0.3,0.3))\n",
        "print(W)\n",
        "print(len(W))   \n",
        "freq={}\n",
        "for i in c:\n",
        "  validation_copy=data_validation.copy()\n",
        "  #print(validation_copy['Target'])\n",
        "  for j in validation_copy.index :\n",
        "    if validation_copy['Target'][j] == i:\n",
        "       validation_copy['Target'][j] = 1\n",
        "    else:\n",
        "       validation_copy['Target'][j] = 0\n",
        "  #print(validation_copy)\n",
        "  #print(np.array(validation_copy['Target']))\n",
        "  mse = []\n",
        "  for j in range(len(alphaarr)):\n",
        "    error,z=(logloss(validation_copy, W, alphaarr[j], rhoarr[j], epocharr[j],1))\n",
        "    mse.append(error)\n",
        "  mini = math.inf\n",
        "  tmp = 0\n",
        "  for j in range(0, len(mse)):\n",
        "    if mse[j] < mini:\n",
        "      mini = mse[j]\n",
        "      tmp = j\n",
        "  if (tmp in freq):\n",
        "    freq[tmp] += 1\n",
        "  else:\n",
        "    freq[tmp] = 1     \n",
        "v = list(freq.values())\n",
        "ke = list(freq.keys())\n",
        "bestIndex = ke[v.index(max(v))]\n",
        "print(\"The best hyperparameters are :\")\n",
        "print(alphaarr[bestIndex])\n",
        "print(rhoarr[bestIndex])\n",
        "print(epocharr[bestIndex])\n",
        "print(bestIndex)\n",
        "#plt.plot(epocharr,mse)\n",
        "#plt.xlabel(\"EPOCHS\")\n",
        "#naming the y axis\n",
        "#plt.ylabel(\"MSE\")\n",
        "#plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      xF   yF   wF   hF  xRE  yRE  xLE  ...   xN   yN  xRM  yRM  xLM  yLM  Target\n",
            "0    292  209  100  112  323  232  367  ...  353  254  332  278  361  278       2\n",
            "1    286  200  109  128  324  235  366  ...  353  258  333  281  361  281       2\n",
            "2    290  204  105  121  325  240  367  ...  351  260  334  282  362  282       2\n",
            "3    287  202  112  118  325  230  369  ...  353  253  335  274  362  275       2\n",
            "4    290  193  104  119  325  224  366  ...  353  244  333  268  363  268       2\n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...\n",
            "601  278  183  128  141  307  218  354  ...  330  247  324  273  356  266       2\n",
            "602  268  186  128  134  296  222  344  ...  319  247  316  274  347  269       1\n",
            "603  264  187  127  131  287  220  334  ...  304  247  305  272  337  270       1\n",
            "604  264  175  143  136  295  207  345  ...  320  234  314  261  351  251       2\n",
            "605  266  170  141  139  303  206  354  ...  331  229  319  255  362  247       2\n",
            "\n",
            "[606 rows x 15 columns]\n",
            "0      2\n",
            "1      2\n",
            "2      2\n",
            "3      2\n",
            "4      2\n",
            "      ..\n",
            "601    2\n",
            "602    1\n",
            "603    1\n",
            "604    2\n",
            "605    2\n",
            "Name: Target, Length: 606, dtype: int64\n",
            "     -1        xF        yF        wF  ...       yRM       xLM       yLM  Target\n",
            "0     1  0.656180  0.469663  0.224719  ...  0.624719  0.811236  0.624719       2\n",
            "1     1  0.642697  0.449438  0.244944  ...  0.631461  0.811236  0.631461       2\n",
            "2     1  0.651685  0.458427  0.235955  ...  0.633708  0.813483  0.633708       2\n",
            "3     1  0.644944  0.453933  0.251685  ...  0.615730  0.813483  0.617978       2\n",
            "4     1  0.651685  0.433708  0.233708  ...  0.602247  0.815730  0.602247       2\n",
            "..   ..       ...       ...       ...  ...       ...       ...       ...     ...\n",
            "601   1  0.624719  0.411236  0.287640  ...  0.613483  0.800000  0.597753       2\n",
            "602   1  0.602247  0.417978  0.287640  ...  0.615730  0.779775  0.604494       1\n",
            "603   1  0.593258  0.420225  0.285393  ...  0.611236  0.757303  0.606742       1\n",
            "604   1  0.593258  0.393258  0.321348  ...  0.586517  0.788764  0.564045       2\n",
            "605   1  0.597753  0.382022  0.316854  ...  0.573034  0.813483  0.555056       2\n",
            "\n",
            "[606 rows x 16 columns]\n",
            "{1, 2, 3}\n",
            "[0.11294920433633088, 0.1372055370852413, 0.19920617073298924, -0.18484771978380815, 0.14757054901364813, -0.03321419173461915, -0.057555232811078494, -0.030217290233682415, -0.01417889456298238, 0.250628706108243, 0.14578172114641857, 0.07359505438290015, -0.03892702479638549, 0.08580420577256215, -0.24384715330857198]\n",
            "15\n",
            "The best hyperparameters are :\n",
            "0.001\n",
            "0.0005\n",
            "80\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvswOojfxQoA"
      },
      "source": [
        "'''\n",
        "TRAINING + OVERFITTING - STARTED\n",
        "'''\n",
        "\n",
        "def trainAndOverFit(classes,w,train_set,validation_set,bestHyperParameterIndex):\n",
        "  ClassW = []\n",
        "  for c in classes:\n",
        "    trainCopy = train_set.copy(deep=True)\n",
        "    trainCopyOutput = list(trainCopy['Target'])\n",
        "\n",
        "    for i in range(len(trainCopyOutput)):\n",
        "      if(trainCopyOutput[i]==c):\n",
        "        trainCopyOutput[i] = 1\n",
        "      else:\n",
        "        trainCopyOutput[i] = 0\n",
        "\n",
        "    trainCopy['Target'] = trainCopyOutput\n",
        "    error,returnedW = logloss(trainCopy,w.copy(),alphaarr[bestHyperParameterIndex],rhoarr[bestHyperParameterIndex],epocharr[bestHyperParameterIndex],'train - class - '+str(c))\n",
        "    # print(error)\n",
        "\n",
        "    ClassW.append(returnedW)\n",
        "\n",
        "    validCopy = validation_set.copy(deep=True)\n",
        "\n",
        "    validCopyOutput = list(validCopy['Target'])\n",
        "\n",
        "    for i in range(len(validCopyOutput)):\n",
        "      if(validCopyOutput[i]==c):\n",
        "        validCopyOutput[i] = 1\n",
        "      else:\n",
        "        validCopyOutput[i] = 0\n",
        "\n",
        "    validCopy['Target'] = validCopyOutput\n",
        "    returnedW,error = logloss(validCopy,w.copy(),alphaarr[bestHyperParameterIndex],rhoarr[bestHyperParameterIndex],epocharr[bestHyperParameterIndex],'validation - class - '+str(c))\n",
        "    # print(error)\n",
        "\n",
        "  return ClassW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTSWK8OGxoID"
      },
      "source": [
        "from sklearn import metrics\n",
        "def logg_predicted(w,x):\n",
        "  return 1/(1+ pow(math.e,-(np.dot(w,x))))\n",
        "\n",
        "def findAccuracy(classes,df,everyClassW):\n",
        "  a = np.array(df.values)\n",
        "  x = a[:,0:len(a[0])-1]\n",
        "  y = a[:,len(a[0])-1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_predicted=[]\n",
        "  correctlyPredicted=0\n",
        "  for i in range(len(a)):\n",
        "    predictedForIthPattern = []\n",
        "    for c in range(3):\n",
        "      predictedForIthPattern.append(logg_predicted(x[i],everyClassW[c]))\n",
        "      \n",
        "    #print(predictedForIthPattern)\n",
        "\n",
        "    # predicting the class.\n",
        "    y_predicted.append(predictedForIthPattern.index(max(predictedForIthPattern))+1)\n",
        "    #print(predictedClass)\n",
        "    \n",
        "    if(y_predicted[i] == y[i]):\n",
        "      correctlyPredicted += 1\n",
        "  print('Correctly Predicted : ',correctlyPredicted)\n",
        "  print('Total Test Samples : ', len(a))\n",
        "  #print('Accuracy : ',(correctlyPredicted*100)/len(a))\n",
        "  print()\n",
        "  \n",
        "  cnf_matrix = metrics.confusion_matrix(y, y_predicted)\n",
        "  print(\"confusion Matrix=\",cnf_matrix)\n",
        "   \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(cnf_matrix)):\n",
        "    print('precision for ',i,' class : ',cnf_matrix[i][i]/(sum(cnf_matrix[i])))\n",
        "\n",
        "  print()\n",
        "\n",
        "  colWiseSum_ConfusionMatrix = np.sum(cnf_matrix,axis=0)\n",
        "  for i in range(len(colWiseSum_ConfusionMatrix)):\n",
        "    print('recall for ',i,' class : ',cnf_matrix[i][i]/(colWiseSum_ConfusionMatrix[i]))\n",
        "\n",
        "  return (correctlyPredicted*100)/len(a)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO-47lAix0v_",
        "outputId": "433c31b8-508c-424f-aa44-2ebe331c2395"
      },
      "source": [
        "everyClassW = trainAndOverFit(c,W,data_train.copy(),data_validation.copy(),bestIndex)\n",
        "print(everyClassW)\n",
        "print(\"****TRAIN - ACCURACY*****\\n\")\n",
        "print(\"Accuracy\",findAccuracy(c,data_train.copy(),everyClassW))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"****TEST - ACCURACY*****\\n\")\n",
        "print(\"Accuracy\",findAccuracy(c,data_test.copy(),everyClassW))\n",
        "\n",
        "print()\n",
        "\n",
        "# '''\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.4269240240749165, -0.22427639468746113, -0.04402949171287178, -0.32107126691715765, -0.005060381589146403, -0.43924312765258533, -0.3335302405759571, -0.4920606617943959, -0.290254233807302, -0.1894515886309163, -0.1594789587915911, -0.34102160717273283, -0.3745517795797807, -0.3697231340059567, -0.579664687950377], [0.2554844451228581, 0.23363692663097602, 0.27478671360352197, -0.14815032692645203, 0.18896379680743927, 0.07629665074913132, 0.025480750640927387, 0.09618858128499144, 0.07066984569762834, 0.3702247258420809, 0.23625178304689784, 0.1861495068546282, 0.06126893863776617, 0.20915734860427704, -0.14277745520971014], [-0.4267976721259471, -0.22405483537655368, -0.043984294614244024, -0.3210428770331537, -0.005013193572924405, -0.4389576032591118, -0.3334835298648275, -0.49178544488317455, -0.29019330025025597, -0.18910570675148441, -0.1594226556501513, -0.340744559085697, -0.37449034003472986, -0.36945935211644415, -0.5795881286056925]]\n",
            "****TRAIN - ACCURACY*****\n",
            "\n",
            "Correctly Predicted :  160\n",
            "Total Test Samples :  181\n",
            "\n",
            "confusion Matrix= [[  0   9   0]\n",
            " [  0 160   0]\n",
            " [  0  12   0]]\n",
            "precision for  0  class :  0.0\n",
            "precision for  1  class :  1.0\n",
            "precision for  2  class :  0.0\n",
            "\n",
            "recall for  0  class :  nan\n",
            "recall for  1  class :  0.8839779005524862\n",
            "recall for  2  class :  nan\n",
            "Accuracy 88.39779005524862\n",
            "\n",
            "****TEST - ACCURACY*****\n",
            "\n",
            "Correctly Predicted :  104\n",
            "Total Test Samples :  119\n",
            "\n",
            "confusion Matrix= [[  0   6   0]\n",
            " [  0 104   0]\n",
            " [  0   9   0]]\n",
            "precision for  0  class :  0.0\n",
            "precision for  1  class :  1.0\n",
            "precision for  2  class :  0.0\n",
            "\n",
            "recall for  0  class :  nan\n",
            "recall for  1  class :  0.8739495798319328\n",
            "recall for  2  class :  nan\n",
            "Accuracy 87.39495798319328\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}